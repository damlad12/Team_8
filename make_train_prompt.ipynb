{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KaibpAAG6G2B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "501ca243-542a-4c3c-c387-c7c6be5791aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 5 fields in line 22, saw 14\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5f98eae926bb>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train_set.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review/userId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review/score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review/summary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review/text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review/productId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset loaded with {len(df)} entries.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 22, saw 14\n"
          ]
        }
      ],
      "source": [
        "!pip install jsonlines\n",
        "import sys\n",
        "import random\n",
        "import pandas as pd\n",
        "import jsonlines\n",
        "import numpy as np\n",
        "import copy\n",
        "import pickle\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "dataset_name = '/content/drive/MyDrive/movies_samples.csv'\n",
        "like_file_path = 'like.txt'\n",
        "dislike_file_path = 'dislike.txt'\n",
        "train_file_path = 'train_set.txt'\n",
        "\n",
        "df = pd.read_csv(dataset_name, header=None, names=['review/userId', 'review/score', 'review/summary', 'review/text', 'product/productId'])\n",
        "print(f\"Dataset loaded with {len(df)} entries.\")\n",
        "\n",
        "isHint = True\n",
        "\n",
        "# Load the dataset\n",
        "root_path = '/content/drive/MyDrive/conventional recommender/dataset'\n",
        "\n",
        "df_like = pd.read_csv('train_set.txt', names=['u', 'i', 'r', 't'], sep=' ')\n",
        "df_dislike = pd.read_csv('dislike.txt', header=None, names=['u', 'i', 'r', 't'])\n",
        "data = pd.read_csv(dataset_name, encoding='ISO-8859-1', sep='\\t')\n",
        "\n",
        "\n",
        "movie_id_list = data['review/productId'].tolist()\n",
        "movie_name_list = data['review/summary'].tolist()\n",
        "\n",
        "movie_name_dict = {movie_id_list[i]: movie_name_list[i] for i in range(len(movie_id_list))}\n",
        "movie_name_dict = data.drop_duplicates(subset='review/productId').set_index('review/productId')['review/summary'].to_dict()\n",
        "\n",
        "\n",
        "df_like_p = pd.read_csv(f'./{dataset_name}/train_set_prediction.csv', usecols=[0, 1, 2, 3])\n",
        "df_like_p.columns = ['u', 'i', 'r','t']\n",
        "\n",
        "\n",
        "def sort_list_reverse_with_indices(lst):\n",
        "        sorted_indices = sorted(enumerate(lst), key=lambda x: x[1], reverse=True)\n",
        "        sorted_indices = [index for index, _ in sorted_indices]\n",
        "        return sorted_indices\n",
        "\n",
        "\n",
        "with open(f'{root_path}/model_res_pkl/{dataset_name}_item.pkl', \"rb\") as file:\n",
        "  cm_item = pickle.load(file)\n",
        "with open(f'{root_path}/model_res_pkl/{dataset_name}_user.pkl', \"rb\") as file:\n",
        "  cm_user = pickle.load(file)\n",
        "with open(f'{root_path}/model_res_pkl/{dataset_name}_pred.pkl', \"rb\") as file:\n",
        "  cm_pred = pickle.load(file)\n",
        "with open(f'{root_path}/model_res_pkl/{dataset_name}_user_emb.pkl', \"rb\") as file:\n",
        "  cm_user_emb = pickle.load(file)\n",
        "\n",
        "with open(f'{root_path}/{dataset_name}/item_id_mapping.pkl', \"rb\") as file:\n",
        "  mf_item = pickle.load(file)\n",
        "with open(f'{root_path}/{dataset_name}/user_id_mapping.pkl', \"rb\") as file:\n",
        "  mf_user = pickle.load(file)\n",
        "with open(f'{root_path}/{dataset_name}/rating_matrix.pkl', \"rb\") as file:\n",
        "  mf_pred = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "mes_list = []\n",
        "gt_list = []\n",
        "\n",
        "user_list = list(df_like['u'].unique())\n",
        "sample_list = []\n",
        "\n",
        "import math\n",
        "\n",
        "weights = [math.log(len(df_like[df_like['u'] == uni])) for uni in user_list]\n",
        "sample_n = len(user_list)\n",
        "\n",
        "if sample_method == 'uniform':\n",
        "        for i in range(sample_n):\n",
        "          sample_ = random.sample(user_list, 1)[0]\n",
        "          sample_list.append(sample_)\n",
        "else:\n",
        "        sample_list1 = []\n",
        "        sample_list2 = []\n",
        "        sample_imp = int(sample_n * 0.6)\n",
        "        for i in range(sample_imp):\n",
        "            sample_ = random.choices(user_list, weights, k=1)[0]\n",
        "            sample_list1.append(sample_)\n",
        "\n",
        "        from sklearn.cluster import KMeans\n",
        "\n",
        "        kmeans = KMeans(n_clusters=10, random_state=0).fit(cm_user_emb)\n",
        "        labels = kmeans.labels_\n",
        "\n",
        "        counts = np.bincount(labels)\n",
        "\n",
        "        samples_per_cluster = np.round(counts / counts.sum() * sample_imp).astype(int)\n",
        "\n",
        "        sampled_ids = []\n",
        "        for cluster_id, samples in enumerate(samples_per_cluster):\n",
        "            cluster_ids = np.where(labels == cluster_id)[0]\n",
        "            sampled_ids.extend(np.random.choice(cluster_ids, samples, replace=True))\n",
        "\n",
        "        mf_user_i = {value: key for key, value in mf_user.items()}\n",
        "        sampled_ids = [mf_user_i[_] for _ in sampled_ids]\n",
        "\n",
        "        sample_list1.extend(sampled_ids)\n",
        "\n",
        "        from collections import Counter\n",
        "\n",
        "        occurrences = Counter(sample_list1)\n",
        "        t_occurrences = {element: 0.95 ** (count - 1) for element, count in occurrences.items()}\n",
        "        sample_list2 = [t_occurrences[_] for _ in sample_list1]\n",
        "\n",
        "        sample_list = random.choices(sample_list1, weights=sample_list2, k=sample_n)\n",
        "\n",
        "        for uni in sample_list:\n",
        "          df = df_like[df_like['u'] == uni]\n",
        "          df_un = df_dislike[df_dislike['u'] == uni]\n",
        "\n",
        "        kws = 'movie'\n",
        "        if len(df) > 1:\n",
        "\n",
        "            '''\n",
        "            Pointwise Ranking\n",
        "            '''\n",
        "            dfp = df_like_p[df_like_p['u'] == uni]\n",
        "            my_list = dfp['i'].tolist()\n",
        "            my_list_r = dfp['r'].tolist()\n",
        "            rndl = [i_ for i_ in range(len(my_list))]\n",
        "            random.shuffle(rndl)\n",
        "\n",
        "            my_list = [(my_list[x]) for x in rndl]\n",
        "            my_list_r = [(my_list_r[x]) for x in rndl]\n",
        "\n",
        "            if len(dfp) > 50:\n",
        "                topk = 50\n",
        "            else:\n",
        "                topk = len(dfp) - 3\n",
        "            trainlist = my_list[:topk]\n",
        "            trainlist_r = my_list_r[:topk]\n",
        "\n",
        "            testlist = my_list[-1:]\n",
        "            testlist_r = my_list_r[-1:]\n",
        "\n",
        "            try:\n",
        "                yy = mf_item[(testlist[0])]\n",
        "                uu = mf_user[(uni)]\n",
        "                mf_lable = mf_pred[uu][yy]\n",
        "            except Exception:\n",
        "                mf_lable = 'Unknown.'\n",
        "                print(1)\n",
        "            historical_interactions = [f'\"{movie_name_dict[i]}\"' for i in trainlist]\n",
        "            answer_items_set = [f'\"{movie_name_dict[i]}\"' for i in testlist]\n",
        "            historical_interactions = [historical_interactions[i_] + ': ' + str(trainlist_r[i_]) + ';' for i_ in\n",
        "                                       range(len(historical_interactions))]\n",
        "            historical_interactions = ' '.join(historical_interactions)\n",
        "            highest_score = 5\n",
        "            instruct0 = f'''You are a {kws} recommender system. Your task is to predict the relevance score to a target {kws} based on the user's historical {kws} ratings. The score should be between 1 and {highest_score}, where 1 is the lowest affinity and {highest_score} is the highest. Respond only with a number between 1 to {highest_score}.\\n\\n'''\n",
        "\n",
        "            instruct1 = f'''User's historical {kws} ratings: <historical interactions>. \\n\\nQuestion: Based on the user's historical ratings, predict the relavance score of the target {kws} <movie> with the user.\\n'''\n",
        "            instruct2 = '''Hint: Another recommender system suggests the answer is <mf_prediction>\"'''\n",
        "            if isHint:\n",
        "                instruct1 = instruct1 + instruct2\n",
        "            instruct1 = instruct1.replace('<historical interactions>', historical_interactions).replace('<movie>',\n",
        "                                                                                                        answer_items_set[\n",
        "                                                                                                            0]).replace(\n",
        "                '<mf_prediction>', str(mf_lable)[:3])\n",
        "\n",
        "            fi = {'messages': [\n",
        "                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"content\": \"\"}]},\n",
        "                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"content\": instruct0 + instruct1}]},\n",
        "                {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"content\": 'Answer: ' + str(testlist_r[0])}]}\n",
        "            ]}\n",
        "            mes_list.append(fi)\n",
        "\n",
        "            '''\n",
        "            Pairwise Ranking\n",
        "            '''\n",
        "            unlikelist = []\n",
        "            if len(df_un) > 0:\n",
        "                my_list = df_un['i'].tolist()\n",
        "                random.shuffle(my_list)\n",
        "                my_list = [(x) for x in my_list]\n",
        "                unlikelist = my_list[:10]\n",
        "            my_list = df['i'].tolist()\n",
        "            random.shuffle(my_list)\n",
        "            my_list = [(x) for x in my_list]\n",
        "            if len(df) > 55:\n",
        "                topk = 50\n",
        "            else:\n",
        "                topk = len(df) - 3\n",
        "            trainlist = my_list[:topk]\n",
        "            testlist = my_list[-1:]\n",
        "            neglist = []\n",
        "            while len(neglist) < 1:\n",
        "                rn = random.sample(movie_id_list, 1)[0]\n",
        "                if not rn in my_list:\n",
        "                    neglist.append(rn)\n",
        "\n",
        "            random_n = (random.random() > 0.5)\n",
        "\n",
        "            historical_interactions = [f'\"{movie_name_dict[i]}\"' for i in trainlist]\n",
        "            false_items_set = [f'\"{movie_name_dict[i]}\"' for i in neglist]\n",
        "            answer_items_set = [f'\"{movie_name_dict[i]}\"' for i in testlist]\n",
        "\n",
        "            try:\n",
        "                xx = cm_item[str(neglist[0])]\n",
        "                yy = cm_item[str(testlist[0])]\n",
        "                uu = cm_user[str(uni)]\n",
        "                if cm_pred[uu][yy] > cm_pred[uu][xx]:\n",
        "                    cm_lable = 'Yes.'\n",
        "                else:\n",
        "                    cm_lable = 'No.'\n",
        "            except Exception:\n",
        "                cm_lable = 'Unknown.'\n",
        "\n",
        "            unlikelist = [x_ for x_ in unlikelist if x_ in movie_name_dict.keys()]\n",
        "\n",
        "            user_unpre = [f'\"{movie_name_dict[i]}\"' for i in unlikelist]\n",
        "\n",
        "            if len(unlikelist) < 3:\n",
        "                user_unpre = 'None.'\n",
        "            else:\n",
        "                user_unpre = ', '.join(user_unpre)\n",
        "\n",
        "            historical_interactions = ', '.join(historical_interactions)\n",
        "            gt_list.append(movie_name_dict[testlist[0]])\n",
        "            if random_n:\n",
        "                first_name = answer_items_set[0]\n",
        "                second_name = false_items_set[0]\n",
        "                tg = 'Yes.'\n",
        "            else:\n",
        "                first_name = false_items_set[0]\n",
        "                second_name = answer_items_set[0]\n",
        "                tg = 'No.'\n",
        "\n",
        "                if cm_lable == 'Yes.':\n",
        "                    cm_lable = 'No.'\n",
        "                elif cm_lable == 'No.':\n",
        "                    cm_lable = 'Yes.'\n",
        "\n",
        "            instruct0 = f'''You are a {kws} recommender system. Based on a user's likes and dislikes, determine if they would prefer one {kws} over another. Respond only with \"Yes.\" or \"No.\".\\n\\n'''\n",
        "\n",
        "            instruct1 = f'''User's Liked {kws}s: <historical interactions>. \\nUser's Disliked {kws}s: <user_unpre>\\n\\nQuestion: Would the user prefer <movie1> over <movie2>?\\n'''\n",
        "            instruct2 = '''Hint: Another recommender system suggests the answer is \"<cm_result>\"'''\n",
        "            if isHint:\n",
        "                instruct1 = instruct1 + instruct2\n",
        "            instruct1 = instruct1.replace('<historical interactions>', historical_interactions).replace('<user_unpre>',\n",
        "                                                                                                        user_unpre).replace(\n",
        "                '<movie1>', first_name).replace('<movie2>', second_name).replace('<cm_result>', cm_lable)\n",
        "\n",
        "            fi = {'messages': [\n",
        "                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"content\": \"\"}]},\n",
        "                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"content\": instruct0 + instruct1}]},\n",
        "                {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"content\": 'Answer: ' + tg}]}\n",
        "            ]}\n",
        "            mes_list.append(fi)\n",
        "            '''\n",
        "            Listwise Ranking\n",
        "            '''\n",
        "\n",
        "            my_list = dfp['i'].tolist()\n",
        "            my_list_r = dfp['r'].tolist()\n",
        "            my_list = [(my_list[x]) for x in rndl]\n",
        "            my_list_r = [(my_list_r[x]) for x in rndl]\n",
        "            largest_rating = 5\n",
        "            second_largest_rating = 4\n",
        "            num_5 = my_list_r.count(largest_rating)\n",
        "            num_4 = my_list_r.count(second_largest_rating)\n",
        "            if num_5 > 3 and num_4 > 2:\n",
        "                idx_5 = [index for index, value in enumerate(my_list) if my_list_r[index] == largest_rating]\n",
        "                idx_4 = [index for index, value in enumerate(my_list) if my_list_r[index] == second_largest_rating]\n",
        "\n",
        "                select_5 = random.sample(idx_5, 3)\n",
        "                select_4 = random.sample(idx_4, 2)\n",
        "\n",
        "                select_5_i = [my_list[__] for __ in select_5]\n",
        "                select_4_i = [my_list[__] for __ in select_4]\n",
        "\n",
        "                user_like_list = []\n",
        "                user_dislike_list = []\n",
        "                for i_ in range(len(my_list)):\n",
        "                    if my_list_r[i_] >= 4 and not (my_list[i_] in select_5 or my_list[i_] in select_4):\n",
        "                        user_like_list.append(my_list[i_])\n",
        "                    elif my_list_r[i_] <= 2:\n",
        "                        user_dislike_list.append(my_list[i_])\n",
        "                if len(user_like_list) > 55:\n",
        "                    topk = 50\n",
        "                user_like_list = user_like_list[:topk]\n",
        "                user_dislike_list = user_dislike_list[:10]\n",
        "\n",
        "                neglist = []\n",
        "                while len(neglist) < 5:\n",
        "                    rn = random.sample(movie_id_list, 1)[0]\n",
        "                    if not (rn in my_list or rn in neglist):\n",
        "                        neglist.append(rn)\n",
        "\n",
        "                total_list = select_5_i + select_4_i + neglist\n",
        "\n",
        "                total_list_mf = []\n",
        "                for j_ in total_list:\n",
        "                    try:\n",
        "                        yy = cm_item[str(j_)]\n",
        "                        uu = cm_user[str(uni)]\n",
        "                        mf_label = mf_pred[uu][yy]\n",
        "                    except Exception:\n",
        "                        mf_label = 1.5\n",
        "                    total_list_mf.append(mf_label)\n",
        "\n",
        "                total_list_mf_idx = sort_list_reverse_with_indices(total_list_mf)\n",
        "                total_list_mf_idx = total_list_mf_idx[:5]\n",
        "                total_list_mf_i = [total_list[k_] for k_ in total_list_mf_idx]\n",
        "\n",
        "                total_list_r = copy.deepcopy(total_list)\n",
        "                random.shuffle(total_list_r)\n",
        "                total_list_t = total_list[:5]\n",
        "\n",
        "                historical_interactions = ', '.join([f'\"{movie_name_dict[i]}\"' for i in user_like_list])\n",
        "                neg_interactions = ', '.join([f'\"{movie_name_dict[i]}\"' for i in user_dislike_list])\n",
        "                true_answer_items_set = ', '.join([f'\"{movie_name_dict[i]}\"' for i in total_list_t])\n",
        "                candidate_item_sets_ = ', '.join([f'\"{movie_name_dict[i]}\"' for i in total_list_r])\n",
        "                mf_item_sets_ = ', '.join([f'\"{movie_name_dict[i]}\"' for i in total_list_mf_i])\n",
        "                instruct0 = f'''You are a {kws} recommender system. Your task is to rank a given list of candidate {kws}s based on user preferences and return the top five recommendations.\\n\\n'''\n",
        "\n",
        "                instruct1 = f'''User's Liked {kws}s: <historical_interactions>. \\nUser's Disliked {kws}s: <user_unpre>\\n\\nQuestion: How would the user rank the candidate item list: <movie_list> based to historical perference?\\n'''\n",
        "                instruct2 = 'Hint: Another recommender model suggests <cm_result>'\n",
        "                if isHint:\n",
        "                    instruct1 = instruct1 + instruct2\n",
        "\n",
        "                instruct1 = instruct1.replace('<historical_interactions>', historical_interactions).replace(\n",
        "                    '<user_unpre>', neg_interactions).replace('<movie_list>', candidate_item_sets_).replace(\n",
        "                    '<cm_result>', mf_item_sets_)\n",
        "\n",
        "                fi = {'messages': [\n",
        "                    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"content\": \"\"}]},\n",
        "                    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"content\": instruct0 + instruct1}]},\n",
        "                    {\"role\": \"assistant\",\n",
        "                     \"content\": [{\"type\": \"text\", \"content\": 'Answer: ' + str(true_answer_items_set)}]}\n",
        "                ]}\n",
        "                mes_list.append(fi)\n",
        "\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "with jsonlines.open('/content/drive/MyDrive/data_all.jsonl', mode='a') as writer:\n",
        "        writer.write_all(mes_list)"
      ]
    }
  ]
}