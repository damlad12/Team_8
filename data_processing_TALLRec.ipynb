{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "PATH_OF_MOVIES = '/content/drive/MyDrive/movies.txt'"
      ],
      "metadata": {
        "id": "GRKaSGgkjicF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bb144c-9f8d-4dc4-85fa-c7bacc3886e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Utu_2PE2O_pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b664cb0e-b14e-4bee-e341-b0f5fe30282c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users with 10 reviews: 1031\n",
            "Filtered sample file created (deduplicated): /content/drive/MyDrive/movies_samples.csv\n",
            "TallRec-compatible data has been saved to 'tallrec_formatted_data.json'.\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n",
            "Total interactions: 686\n",
            "Data has been split and saved into 'train_movie.json', 'valid_movie.json', and 'test_movie.json'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import html\n",
        "from html import escape\n",
        "\n",
        "\n",
        "file_path = PATH_OF_MOVIES\n",
        "sample_file_path = '/content/drive/MyDrive/movies_samples.csv'\n",
        "# Initialize variables\n",
        "parsed_data = []\n",
        "user_review_counts = {}\n",
        "record_count = 0\n",
        "max_records = 800000  # adjust as needed\n",
        "\n",
        "# Step 1: Parse the file and accumulate review counts\n",
        "with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
        "    record = {}\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            if record:\n",
        "                user_id = record.get('review/userId', None)\n",
        "                if user_id:\n",
        "                    user_review_counts[user_id] = user_review_counts.get(user_id, 0) + 1\n",
        "                parsed_data.append({\n",
        "                    \"review/userId\": record.get('review/userId'),\n",
        "                    \"review/score\": float(record.get('review/score', 0)),\n",
        "                    \"review/summary\": record.get('review/summary'),\n",
        "                    \"review/text\" : record.get('review/text'),\n",
        "                    \"review/productId\" : record.get('product/productId'),\n",
        "                    \"review/time\": record.get('review/time')\n",
        "                })\n",
        "                record = {}\n",
        "                record_count += 1\n",
        "                if record_count >= max_records:\n",
        "                    break\n",
        "        elif \":\" in line:\n",
        "            key, value = line.split(\":\", 1)\n",
        "            record[key.strip()] = value.strip()\n",
        "\n",
        "# Step 2: Identify users with exactly 10 reviews\n",
        "users_with_10_reviews = {user for user, count in user_review_counts.items() if count == 10}\n",
        "\n",
        "print(f\"Number of users with 10 reviews: {len(users_with_10_reviews)}\")\n",
        "\n",
        "# Step 3: Filter the parsed data for these users\n",
        "filtered_data = [r for r in parsed_data if r.get('review/userId') in users_with_10_reviews]\n",
        "\n",
        "# Step 4: Convert to DataFrame\n",
        "df = pd.DataFrame(filtered_data)\n",
        "df = df.sort_values(by=['review/userId', 'review/time'])\n",
        "\n",
        "# Drop duplicates before saving\n",
        "df = df.drop_duplicates(subset=['review/summary'])\n",
        "df = df.drop_duplicates(subset=['review/text'])\n",
        "df.to_csv(sample_file_path, sep='\\t', index=False, encoding='ISO-8859-1')\n",
        "print(f\"Filtered sample file created (deduplicated): {sample_file_path}\")\n",
        "\n",
        "# Now read the deduplicated file\n",
        "data = pd.read_csv(sample_file_path, encoding='ISO-8859-1', sep='\\t')\n",
        "data = data.sort_values(by=['review/userId', 'review/time'])\n",
        "\n",
        "# Define rating threshold\n",
        "preference_threshold = 4.0\n",
        "\n",
        "user_preferences = defaultdict(list)\n",
        "user_unpreferences = defaultdict(list)\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    user_id = row['review/userId']\n",
        "    #movie_info = row['review/text']\n",
        "    movie_info = f\"{row['review/productId']}: {row['review/summary']}\"\n",
        "    rating = row['review/score']\n",
        "    if rating >= preference_threshold:\n",
        "        user_preferences[user_id].append(movie_info)\n",
        "    else:\n",
        "        user_unpreferences[user_id].append(movie_info)\n",
        "\n",
        "tallrec_data = []\n",
        "\n",
        "for user_id, group in data.groupby('review/userId'):\n",
        "    if not user_preferences[user_id] or not user_unpreferences[user_id]:\n",
        "        continue\n",
        "    user_group = group.sort_values(by='review/time')\n",
        "    #example_movie = user_group.iloc[-1]['review/text']\n",
        "    example_movie = f\"{user_group.iloc[-1]['review/productId']}: {user_group.iloc[-1]['review/summary']}\"\n",
        "\n",
        "    output_label = \"Yes.\" if example_movie in user_preferences[user_id] else \"No.\"\n",
        "    if example_movie in user_preferences[user_id]:\n",
        "        user_preferences[user_id].remove(example_movie)\n",
        "    if example_movie in user_unpreferences[user_id]:\n",
        "        user_unpreferences[user_id].remove(example_movie)\n",
        "    data = data.drop(user_group.iloc[-1].name)\n",
        "    unique_prefs = list(set(user_preferences[user_id]))\n",
        "    unique_unprefs = list(set(user_unpreferences[user_id]))\n",
        "\n",
        "    '''example = {\n",
        "    \"instruction\": html.unescape(\"Given the user's preference and unpreference, identify whether the user will like the target movie by answering \\\"Yes.\\\" or \\\"No.\\\".\"),\n",
        "    \"input\": html.unescape(f\"User Preference: {', '.join(unique_prefs)}\\nUser Unpreference: {', '.join(unique_unprefs)}\\nWhether the user will like the target movie \\\"{example_movie}\\\"?\"),\n",
        "    \"output\": output_label\n",
        "    }'''\n",
        "    example = {\n",
        "        \"instruction\": html.unescape(\"Given the user's preference and unpreference, identify whether the user will like the target movie by answering \\\"Yes.\\\" or \\\"No.\\\".\"),\n",
        "        \"input\": html.unescape(\n",
        "            f\"User Preference: {', '.join(unique_prefs)}\\n\"\n",
        "            f\"User Unpreference: {', '.join(unique_unprefs)}\\n\"\n",
        "            f\"Whether the user will like the target movie \\\"{example_movie}\\\"?\"\n",
        "        ),\n",
        "        \"output\": output_label\n",
        "    }\n",
        "\n",
        "    tallrec_data.append(example)\n",
        "\n",
        "tallrec_df = pd.DataFrame(tallrec_data)\n",
        "tallrec_df.reset_index(drop=True, inplace=True)\n",
        "# Deduplicate the final tallrec data\n",
        "tallrec_df = tallrec_df.drop_duplicates(subset=['instruction','input','output'])\n",
        "tallrec_df.to_json('tallrec_formatted_data.json', orient='records', lines=True)\n",
        "\n",
        "print(\"TallRec-compatible data has been saved to 'tallrec_formatted_data.json'.\")\n",
        "\n",
        "# Split into train, valid, test\n",
        "!pip install jsonlines\n",
        "import json\n",
        "import jsonlines\n",
        "\n",
        "tallrec_file_path = \"tallrec_formatted_data.json\"\n",
        "\n",
        "data = []\n",
        "with jsonlines.open(tallrec_file_path, 'r') as reader:\n",
        "    for obj in reader:\n",
        "        data.append(obj)\n",
        "\n",
        "total_interactions = len(data)\n",
        "print(f\"Total interactions: {total_interactions}\")\n",
        "\n",
        "train_end = int(0.8 * total_interactions)\n",
        "val_end = train_end + int(0.1 * total_interactions)\n",
        "\n",
        "train_data = data[:train_end]\n",
        "validation_data = data[train_end:val_end]\n",
        "test_data = data[val_end:]\n",
        "\n",
        "with open('train_movie.json', 'w') as file:\n",
        "    json.dump(train_data, file, indent=2)\n",
        "\n",
        "with open('valid_movie.json', 'w') as file:\n",
        "    json.dump(validation_data, file, indent=2)\n",
        "\n",
        "with open('test_movie.json', 'w') as file:\n",
        "    json.dump(test_data, file, indent=2)\n",
        "\n",
        "print(\"Data has been split and saved into 'train_movie.json', 'valid_movie.json', and 'test_movie.json'.\")\n"
      ]
    }
  ]
}